{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "research.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Interpause/pseudo-text/blob/master/research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hm8XD_Pm4psw",
        "colab_type": "text"
      },
      "source": [
        "# Overview\n",
        "If you got here from my repository [Interpause/pseudo-text](https://github.com/Interpause/pseudo-text), you would know these datasets are related to fake news. Fake news classifiers generally fall into three categories: content-based, context-based and style-based. I generally got datasets related to all these, suitable for a range of approaches from claim comparison to credibility calculation to style analysis.<br><br>\n",
        "Tasks:\n",
        "* [free categorized 50k++ dataset](https://www.datahub.io)\n",
        "* Write about your own 12k dataset\n",
        "* https://archive.ics.uci.edu/ml/datasets/Reuters-21578+Text+Categorization+Collection\n",
        "* http://qwone.com/~jason/20Newsgroups/\n",
        "* SemanticScholar\n",
        "\n",
        "I do everything online now down to even storage of datasets... Has this made me a better coder? \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GYknk3V5XWY",
        "colab_type": "text"
      },
      "source": [
        "# Fake News Datasets\n",
        "A lot of scraping will be required. <br>\n",
        "---\n",
        "extra:\n",
        "- https://archive.ics.uci.edu/ml/datasets/Health+News+in+Twitter\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkptVinUvQol",
        "colab_type": "text"
      },
      "source": [
        "## Overview\n",
        "Open to see scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3XZibKC6vabT",
        "colab_type": "text"
      },
      "source": [
        "[Dataset dataset](https://arxiv.org/pdf/1811.00770.pdf)<br>\n",
        "is using clustering to extract a fake news dataset plain bad?\n",
        "![Results using different methods on datasets](https://i.imgur.com/sop3y4Q.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EnnoRoG9KN4",
        "colab_type": "text"
      },
      "source": [
        "## FakeNewsNet\n",
        "https://github.com/KaiDMML/FakeNewsNet<br>https://arxiv.org/abs/1809.01286<br>\n",
        "* source: politifact, gossipcop (problematic? TODO), twitter<br>\n",
        "* samples: actually damn little, not homogenous either <br>\n",
        "\n",
        "### Minimal\n",
        "* features: url, title, tweet_ids (true/false separated different CSVs)<br>\n",
        "* uses: headlines dataset<br>\n",
        "\n",
        "### Full\n",
        "* features: article, tweets, retweets, user_profile, user_timeline_tweets, followers, following<br>\n",
        "* uses: content dataset, credibility calculation, realistic dataset, everything<br><br>\n",
        "\n",
        "Essentially, a very good scrape of twitter. Issue is scraper has to be manually run over along time. Allows custom approaches where users can be further traced than dataset scraper does. Allows for active scrapping during training? Quite good as its real world data.\n",
        "![Dataset test scores](https://i.imgur.com/wsR0FAC.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEiWaz9BK8yw",
        "colab_type": "text"
      },
      "source": [
        "## Buzzfeed\n",
        "https://github.com/BuzzFeedNews/2018-12-fake-news-top-50<br>\n",
        "* source: buzzfeed, Lead Stories (fact checker)<br>\n",
        "* features: title, url, fb_engagement, date, category, source<br>\n",
        "* features: top 50 fake news articles, lists of fake news sites<br>\n",
        "* usage: content dataset, demo <br>\n",
        "\n",
        "Will need a lot of scrapping. Hey at least those sites probably don't have bot protection.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Ex7CwKiIodk",
        "colab_type": "text"
      },
      "source": [
        "## Claims Comparison\n",
        "https://www.kaggle.com/c/fake-news/data<br>\n",
        "* source: unknown (TODO)<br>\n",
        "* samples: 26k <br>\n",
        "* features: title, author, text, label<br>\n",
        "\n",
        "https://www.kaggle.com/c/fake-news-pair-classification-challenge/data<br>\n",
        "* source: unknown (TODO)<br>\n",
        "* features: true headline, another headline<br>\n",
        "* labels: same message, refuting, or unrelated<br>\n",
        "* samples: 400k<br>\n",
        "\n",
        "https://github.com/FakeNewsChallenge/fnc-1<br>\n",
        "* source: unknown (TODO)<br>\n",
        "* features: headline, paragraph<br>\n",
        "* labels: agree, disagree, neutral, unrelated<br>\n",
        "* samples: 50k\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKm5-EYnHCrF",
        "colab_type": "text"
      },
      "source": [
        "## LIAR\n",
        "https://github.com/thiagorainmaker77/liar_dataset<br>\n",
        "https://arxiv.org/abs/1705.00648<br>\n",
        "* source: politifact (problematic? TODO)<br>\n",
        "* features: statement, topics, speaker, job title, state, party, truth counts, context<br>\n",
        "* usage: claims dataset<br>\n",
        "\n",
        "I have been playing with this dataset. Statements after pre-processing tend to be too short for anything aside from headlines. Dataset as a whole too simple to do much. \n",
        "<br>\n",
        "Similar: https://github.com/compsocial/CREDBANK-data <br>\n",
        "Downloading takes forever & requires amazon S3, scrapping takes even longer.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1FKmYL85mOd",
        "colab_type": "text"
      },
      "source": [
        "# True News Datasets\n",
        "Hey is that a 1.5Gb dataset? We don't need nothing else (ram explodes)<br>\n",
        "More data has been found: https://webhose.io/free-datasets/news-articles-by-topics/<br>\n",
        "Im scrapping even more data using a scrapper library i found\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IrgD7KyMl3U",
        "colab_type": "text"
      },
      "source": [
        "## All the News\n",
        "https://components.one/datasets/all-the-news-articles-dataset/<br>\n",
        "* samples: 204k<br>\n",
        "* features: title, text, publication<br>\n",
        "\n",
        "Its a really large SQLlite database of more news than we will ever need."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nj1q28jNN22H",
        "colab_type": "text"
      },
      "source": [
        "## Million Headlines\n",
        "https://www.kaggle.com/therohk/million-headlines<br>\n",
        "* samples: it says it in the title<br>\n",
        "\n",
        "It mite be too australian mate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5RkF87pOfvF",
        "colab_type": "text"
      },
      "source": [
        "## News Aggregator Dataset\n",
        "https://www.kaggle.com/uciml/news-aggregator-dataset<br>\n",
        "* samples: 423k<br>\n",
        "* features: headlines, URL, category<br>\n",
        "\n",
        "Requires manual scrap, urls may not be intact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeeEHRHOPBTl",
        "colab_type": "text"
      },
      "source": [
        "## News Category Dataset\n",
        "https://www.kaggle.com/rmisra/news-category-dataset<br>\n",
        "* samples: 200k<br>\n",
        "* features: headlines, category<br>\n",
        "\n",
        "Sourced primarily from HuffPost."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13dbWedk9oWv",
        "colab_type": "text"
      },
      "source": [
        "# Literature Review\n",
        "Not included out of courtesy, but actual useful reference or seems like a promising read.\n",
        "\n",
        "---\n",
        "\n",
        "Overview:\n",
        "* [Understanding the Promise and Limits of Automated Face-Checking](https://ora.ox.ac.uk/objects/uuid:f321ff43-05f0-4430-b978-f5f517b73b9b/download_file?file_format=pdf&safe_filename=graves_factsheet_180226%2BFINAL.pdf&type_of_work=Report)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3piMedPVltm",
        "colab_type": "text"
      },
      "source": [
        "## Content-based\n",
        "* Bag of words (tfidf) and then cluster (done)\n",
        "* Pre-trained ELMo, sum word embeddings & cluster\n",
        "* Claim extraction & comparison\n",
        "    * scrape relevant evidence from internet\n",
        "    * learn facts using large network\n",
        "* Extract raw content, feed gigabytes of content to transformer that has black magic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4FT8B4LWyhg",
        "colab_type": "text"
      },
      "source": [
        "### Links\n",
        "- [Good slides](http://wtlab.um.ac.ir/files/seminars/Rezaei-1398-07-10.pdf)\n",
        "- [ClaimBuster](https://idir.uta.edu/claimbuster/) Good comparison?\n",
        "- https://idir.uta.edu/src/projects.html components of fake news detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxI7tSTkkxa0",
        "colab_type": "text"
      },
      "source": [
        "### Subject Predicate Object graphs?\n",
        "- Synonym substitution (including names)\n",
        "- Time stamping (remove obsolete; contextualize to different times)\n",
        "- Graph link credibility must be stored; hide conflicting data from less credible sources\n",
        "- Spacy can do some part of this"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "et7tQtMIVmY0",
        "colab_type": "text"
      },
      "source": [
        "## Style-based\n",
        "* Vader social media sentiment analysis\n",
        "* Train transformer on a lot of reviews\n",
        "* Possible to extract information outside of positive or negative? (deadset hard to find)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5soCFu5YVl-1",
        "colab_type": "text"
      },
      "source": [
        "## Context-based\n",
        "* Credibility of poster. Credibility of those liking post, their ratings too. I think the UFD one sounds really solid but I am not sure if there is better.\n",
        "* What I proposed but later dropped, actually following interactions between users to determine which users are generally trustable for different topics. Require topic classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DDTXlkX-VPv",
        "colab_type": "text"
      },
      "source": [
        "### News tweets classification with good filtering\n",
        "[Unsupervised Fake News Detection on Social Media:\n",
        "A Generative Approach](http://www.public.asu.edu/~skai2/files/aaai_2019_unsupervised.pdf)<br>\n",
        "Context-based & style-based. Innovative credibility calculation. <br><br>\n",
        "Sentiment analysis only on verified user replies. Credibility calculated by post statistics of said replies. Likes and blank retweets are taken as positive. \"off-the-shelf\" sentiment analysis assuming positive means true, negative means false. 75.9% accuracy on Liar + Buzzfeed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIc9jGx7VQRP",
        "colab_type": "text"
      },
      "source": [
        "# Approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbnt0rUB4Kgs",
        "colab_type": "text"
      },
      "source": [
        "## Checker\n",
        "* Find odd one out\n",
        "    * Fake news should be seen as true if all references are fake (sabotage datset)\n",
        "* Claim extraction + Comparison\n",
        "* Done via pre-trained/blank BERT\n",
        "    * Does find odd one out take away power of implicit sentiment & credibility analysis?\n",
        "* [Knowledge graphs](http://ceur-ws.org/Vol-2322/dsi4-6.pdf)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJLEsNQd5fct",
        "colab_type": "text"
      },
      "source": [
        "## Finder\n",
        "* Recommender system?\n",
        "* no-train keyword/category/date comparison?\n",
        "* Clustering?\n",
        "* Force one from certain sources?\n",
        "* Throw away similar/copied articles?\n",
        "* Hand-curate through use of weaker find algorithm & confirm with human?\n",
        "* Find all news dataset + categories + tagging for offline mode?\n",
        "    * Dual offline check/online find if don't have?\n",
        "* Are newer articles more reliable?\n",
        "* How to prevent finding exactly the same?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhI0AZFZVVyk",
        "colab_type": "text"
      },
      "source": [
        "### Proto Idea 1\n",
        "- feature extraction of examined to find true articles (online >>> offline)\n",
        "    - tfidf + SVM, headlines, paraphrase model, categorizer, name extraction\n",
        "    - soo BERT might be [good enough without fine-tuning](https://medium.com/the-artificial-impostor/news-topic-similarity-measure-using-pretrained-bert-model-1dbfe6a66f1d)\n",
        "    - Efficient methods find large pool of roughly similar true articles, BERT proceeds to narrow them down (include timestamps)\n",
        "    - May not use ALBERT, BERT may only be good at above because it was trained on NSP... though ALBERT can be retrained since its smaller so....\n",
        "- all articles are paraphrased; agree/refute/unrelated classifier used\n",
        "- selected articles sent to BERT (send paraphrased?) trained on fact check\n",
        "\n",
        "Might work as each step (paraphraser, refute classifier) has dataset to be trained separately with. Doesn't utilize knowledge graphs.<br>\n",
        "Current main focus on finder which finds related evidence (only credible; not necessarily for or against) from statements to compile easily human checkable dataset. Performance benchmarkable by human or by using Checker (when assuming Checker is perfect)<br>\n",
        "Checker may end up being someone else's model, idea is to use BERT to improve current state of the art which is just LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLgDsBdljFX3",
        "colab_type": "text"
      },
      "source": [
        "State of art text similarity finder doesn't use vectors? <br>\n",
        "remove adjectives and adverbs from keywords to help in finding range of answers rather than similar?\n",
        "[An explanation and ranking of various approaches to text similarity](https://medium.com/@adriensieg/text-similarities-da019229c894)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAZVIzIP8phG",
        "colab_type": "text"
      },
      "source": [
        "How to judge??????<br>\n",
        "there were way too many approaches I wanted to try: but honestly what motivates me most is to play with the cutting edge. We can use other people's code for the benchmarks later.<br>\n",
        "Unfortunately, due to time limitations I shall not be exploring knowledge graph approaches. (oh wait thats stage 2 anyways how did i digress)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfLMrWBZVj2K",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZoLUewQVjyu",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}