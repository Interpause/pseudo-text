{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5x0RHPSwpIjV",
        "XXpLLN9JpdnY"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Interpause/pseudo-text/blob/master/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5x0RHPSwpIjV",
        "colab_type": "text"
      },
      "source": [
        "# Imports & setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozUqLnAISSFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "\n",
        "from collections import OrderedDict\n",
        "import string, json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz1SkOvjTeIR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "8a611c28-b77a-4bd3-a70f-3c6d0daa1cb2"
      },
      "source": [
        "from google.colab import drive #drive.flush_and_unmount() #drive.flush()\n",
        "import os\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/CSIT Internship/code')\n",
        "nltk.download('all',quiet=True)\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Wed Nov 27 02:42:08 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACQz9f2QpRVQ",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-9sZYE3SSFW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# List of all words to remove from statements\n",
        "removables = []\n",
        "removables += nltk.corpus.stopwords.words('english')\n",
        "removables += [w.lower() for w in nltk.corpus.names.words()]\n",
        "removables += ['hi','trump']\n",
        "\n",
        "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
        "#data fed to vectorizer is already cleaned but maybe TODO use their params instead\n",
        "vectorizer = TfidfVectorizer(max_features=400) #gets kwords on principle of very used in doc, but rare across all docs\n",
        "#vectorizer = CountVectorizer(max_features=400) #gets kwords by frequency distribution (is not smart)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZvVBqAwSSFb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#much info was lost\n",
        "#some of these could be specified as options to the Tfidf vectorizer instead\n",
        "def filterSent(s):\n",
        "    s = s.lower()\n",
        "    s = nltk.word_tokenize(s) #split into list of words intelligently\n",
        "    s = tuple(lemmatizer.lemmatize(w) for w in s if w.isalpha()) #supposed to lemmatize words (aka get basic form)\n",
        "    s = tuple(w for w in s if w not in removables) #remove removables\n",
        "    return ' '.join(s)\n",
        "filterSent(\"hi there my name is jOhn henry battery car dead better programming\")\n",
        "\n",
        "#applied to dataset to reformat data\n",
        "formatter = lambda x:(filterSent(x.statement),liar_score[x.label])\n",
        "\n",
        "def printScore(y_pred,y_test):\n",
        "    #assuming balanced, otherwise using balanced_accuracy_score()\n",
        "    print(\"Accuracy: {0:.1%}\".format(metrics.accuracy_score(y_test, y_pred)))\n",
        "    #TODO add more"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXpLLN9JpdnY",
        "colab_type": "text"
      },
      "source": [
        "# LIAR dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLf1yZEXSSFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_to_liar = './raw/liar_dataset/'\n",
        "#counts refer to the speaker's reliability as a whole, interestingly excluding true counts. \n",
        "liar_headers = ('id','label','statement',\n",
        "                'subjects','speaker','job_title',\n",
        "                'state','party','barely_true_counts',\n",
        "                'false_counts','half_true_counts','mostly_true_counts',\n",
        "                'pants_on_fire_counts','context')\n",
        "\n",
        "liar_score = {'true':1,\n",
        "              'mostly-true':1,\n",
        "              'half-true':1,\n",
        "              'barely-true':0,\n",
        "              'false':0,\n",
        "              'pants-fire':0\n",
        "             }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEIZsaT3SSFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Opens dataset, extracts only statement & label and reformats them using formatter()\n",
        "liar_train = pd.read_csv(path_to_liar+'train.tsv',delimiter='\\t',header=None,names=liar_headers)\n",
        "traindf = liar_train.loc[:,('statement','label')].apply(formatter,axis=1,result_type='broadcast')\n",
        "liar_test = pd.read_csv(path_to_liar+'test.tsv',delimiter='\\t',header=None,names=liar_headers)\n",
        "testdf = liar_test.loc[:,('statement','label')].apply(formatter,axis=1,result_type='broadcast')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABncuU-7pq-p",
        "colab_type": "text"
      },
      "source": [
        "# Bag of Words + SVM approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WO9wm6lSSFt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "a663f829-5c72-42e9-fcf2-c29be87d26aa"
      },
      "source": [
        "#trains vectorizer on training dataset, followed by transforming training dataset into vectors\n",
        "train_data = vectorizer.fit_transform(traindf.statement)\n",
        "x_train = train_data.toarray()\n",
        "y_train = np.array(traindf.label,dtype=int)\n",
        "#transforms test dataset into vectors without training\n",
        "test_data = vectorizer.transform(testdf.statement)\n",
        "x_test = test_data.toarray()\n",
        "y_test = np.array(testdf.label, dtype=int)\n",
        "#see which keywords were extracted as features\n",
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['abortion', 'according', 'act', 'actually', 'administration', 'affordable', 'agency', 'ago', 'allow', 'allowed', 'almost', 'already', 'also', 'amendment', 'america', 'american', 'among', 'amount', 'attack', 'average', 'away', 'back', 'background', 'ban', 'bank', 'barack', 'benefit', 'big', 'billion', 'black', 'board', 'border', 'break', 'brown', 'budget', 'bush', 'business', 'buy', 'california', 'called', 'came', 'campaign', 'candidate', 'cant', 'car', 'care', 'cent', 'change', 'check', 'child', 'china', 'citizen', 'city', 'class', 'college', 'combined', 'come', 'community', 'company', 'congress', 'congressional', 'congressman', 'control', 'cost', 'could', 'country', 'county', 'court', 'coverage', 'create', 'created', 'credit', 'crime', 'criminal', 'current', 'cut', 'day', 'deal', 'death', 'debate', 'debt', 'decade', 'defense', 'deficit', 'democrat', 'democratic', 'department', 'didnt', 'district', 'doesnt', 'dollar', 'done', 'dont', 'doubled', 'drug', 'due', 'economic', 'economy', 'education', 'eight', 'elected', 'election', 'employee', 'end', 'energy', 'entire', 'even', 'ever', 'every', 'executive', 'fact', 'failed', 'family', 'far', 'federal', 'financial', 'first', 'five', 'food', 'force', 'foreign', 'former', 'found', 'four', 'free', 'fund', 'funding', 'gas', 'gave', 'general', 'get', 'getting', 'give', 'given', 'go', 'going', 'gone', 'got', 'gov', 'government', 'governor', 'great', 'group', 'growth', 'gun', 'ha', 'half', 'health', 'help', 'helped', 'high', 'higher', 'highest', 'history', 'home', 'hour', 'house', 'illegal', 'immigrant', 'immigration', 'including', 'income', 'increase', 'increased', 'individual', 'industry', 'insurance', 'interest', 'iran', 'iraq', 'island', 'issue', 'ive', 'jersey', 'keep', 'kid', 'killed', 'know', 'largest', 'last', 'law', 'le', 'leader', 'least', 'left', 'legislation', 'legislature', 'let', 'level', 'life', 'like', 'lobbyist', 'local', 'lost', 'lot', 'lower', 'lowest', 'made', 'majority', 'make', 'making', 'man', 'mandate', 'many', 'marijuana', 'marriage', 'massachusetts', 'mccain', 'mean', 'medicaid', 'medical', 'medicare', 'member', 'men', 'mexico', 'middle', 'military', 'million', 'milwaukee', 'minimum', 'mitt', 'money', 'month', 'much', 'muslim', 'nation', 'national', 'nearly', 'need', 'never', 'new', 'next', 'north', 'nothing', 'nuclear', 'number', 'obama', 'obamacare', 'obamas', 'office', 'official', 'ohio', 'oil', 'one', 'opposed', 'oregon', 'paid', 'parenthood', 'part', 'party', 'passed', 'past', 'pay', 'paying', 'pension', 'people', 'per', 'percent', 'person', 'place', 'plan', 'planned', 'point', 'police', 'policy', 'political', 'poll', 'population', 'position', 'poverty', 'power', 'president', 'presidential', 'private', 'program', 'project', 'property', 'proposal', 'proposed', 'public', 'put', 'raise', 'raised', 'raising', 'rate', 'received', 'recent', 'record', 'reform', 'report', 'republican', 'resident', 'result', 'revenue', 'rhode', 'right', 'romney', 'rubio', 'rule', 'run', 'running', 'said', 'salary', 'sale', 'save', 'school', 'second', 'secretary', 'sector', 'security', 'seen', 'senate', 'senator', 'senior', 'sent', 'service', 'seven', 'show', 'signed', 'since', 'single', 'six', 'small', 'social', 'spend', 'spending', 'spent', 'state', 'still', 'stimulus', 'stop', 'street', 'student', 'study', 'support', 'supported', 'supreme', 'system', 'take', 'taken', 'taking', 'tax', 'taxpayer', 'teacher', 'term', 'terrorist', 'texas', 'thats', 'theyre', 'thing', 'think', 'thousand', 'three', 'time', 'today', 'took', 'top', 'total', 'trade', 'trillion', 'troop', 'tuition', 'twice', 'two', 'unemployment', 'union', 'united', 'university', 'use', 'used', 'veteran', 'vote', 'voted', 'voter', 'voting', 'wa', 'wage', 'wall', 'want', 'war', 'water', 'weapon', 'week', 'went', 'weve', 'whether', 'white', 'wisconsin', 'without', 'woman', 'work', 'worker', 'working', 'world', 'worst', 'would', 'year', 'york', 'young', 'youre']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Rirubr1SSF0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "79b8ee51-3da2-4636-8825-7322318b2b15"
      },
      "source": [
        "#fits SVM on vectorized training dataset\n",
        "clf = SVC(kernel='linear')\n",
        "clf.fit(x_train,y_train)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
              "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
              "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
              "    shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJ9Q0csBSSF-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "14295006-b641-4eb2-c9ea-db527580286e"
      },
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "printScore(y_pred,y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 60.8%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKCvTuIeq_8m",
        "colab_type": "text"
      },
      "source": [
        "# ELMo Sum approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TumS9NkSSF7",
        "colab_type": "code",
        "colab": {},
        "outputId": "c7145d43-92ca-477f-deea-376ea3cc9d3b"
      },
      "source": [
        "sentences[20 < sentences.map(len) < 50]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-18-997828254401>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1553\u001b[0m             \u001b[1;34m\"The truth value of a {0} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m             \"Use a.empty, a.bool(), a.item(), a.any() or a.all().\".format(\n\u001b[1;32m-> 1555\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1556\u001b[0m             )\n\u001b[0;32m   1557\u001b[0m         )\n",
            "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASfwlsEmSSFO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "options_file = \"./elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "weight_file = \"./elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "elmo = Elmo(options_file, weight_file, 1, dropout=0) #1 representation only\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUEtTSxZSSF3",
        "colab_type": "code",
        "colab": {},
        "outputId": "77e37941-a971-4972-aa46-6b41c64e34d7"
      },
      "source": [
        "'''\n",
        "#I would try this if i hadnt almost immediately crashed from lag. maybe its cause its padded. ill take data points within a length range then\n",
        "sentences = traindf.statement.str.split()\n",
        "character_ids = batch_to_ids(sentences)\n",
        "embeddings = elmo(character_ids) #[representation][sent_no][word_no (padded)]\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "$ Torch: not enough memory: you tried to allocate 7GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-13-10818fed55d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraindf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcharacter_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_to_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melmo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharacter_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#[representation][sent_no][word_no (padded)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;31m# run the biLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mbilm_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreshaped_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreshaped_word_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[0mlayer_activations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'activations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mmask_with_bos_eos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[0;32m    605\u001b[0m                 \u001b[0mtype_representation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'token_embedding'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0mtoken_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_token_embedder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[0mtype_representation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'token_embedding'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolutions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'char_conv_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m             \u001b[0mconvolved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharacter_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m             \u001b[1;31m# (batch_size * sequence_length, n_filters for this width)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0mconvolved\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvolved\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 187\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 7GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5d8dca3f-7a36-4076-f1ad-6d6ddf240104",
        "id": "VNPjhX5oltXB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['abortion',\n",
              " 'according',\n",
              " 'act',\n",
              " 'actually',\n",
              " 'administration',\n",
              " 'affordable',\n",
              " 'agency',\n",
              " 'ago',\n",
              " 'allow',\n",
              " 'allowed',\n",
              " 'almost',\n",
              " 'already',\n",
              " 'also',\n",
              " 'amendment',\n",
              " 'america',\n",
              " 'american',\n",
              " 'among',\n",
              " 'amount',\n",
              " 'attack',\n",
              " 'average',\n",
              " 'away',\n",
              " 'back',\n",
              " 'background',\n",
              " 'ban',\n",
              " 'bank',\n",
              " 'barack',\n",
              " 'benefit',\n",
              " 'big',\n",
              " 'billion',\n",
              " 'black',\n",
              " 'board',\n",
              " 'border',\n",
              " 'break',\n",
              " 'brown',\n",
              " 'budget',\n",
              " 'bush',\n",
              " 'business',\n",
              " 'buy',\n",
              " 'california',\n",
              " 'called',\n",
              " 'came',\n",
              " 'campaign',\n",
              " 'candidate',\n",
              " 'cant',\n",
              " 'car',\n",
              " 'care',\n",
              " 'cent',\n",
              " 'change',\n",
              " 'check',\n",
              " 'child',\n",
              " 'china',\n",
              " 'citizen',\n",
              " 'city',\n",
              " 'class',\n",
              " 'college',\n",
              " 'combined',\n",
              " 'come',\n",
              " 'community',\n",
              " 'company',\n",
              " 'congress',\n",
              " 'congressional',\n",
              " 'congressman',\n",
              " 'control',\n",
              " 'cost',\n",
              " 'could',\n",
              " 'country',\n",
              " 'county',\n",
              " 'court',\n",
              " 'coverage',\n",
              " 'create',\n",
              " 'created',\n",
              " 'credit',\n",
              " 'crime',\n",
              " 'criminal',\n",
              " 'current',\n",
              " 'cut',\n",
              " 'day',\n",
              " 'deal',\n",
              " 'death',\n",
              " 'debate',\n",
              " 'debt',\n",
              " 'decade',\n",
              " 'defense',\n",
              " 'deficit',\n",
              " 'democrat',\n",
              " 'democratic',\n",
              " 'department',\n",
              " 'didnt',\n",
              " 'district',\n",
              " 'doesnt',\n",
              " 'dollar',\n",
              " 'done',\n",
              " 'dont',\n",
              " 'doubled',\n",
              " 'drug',\n",
              " 'due',\n",
              " 'economic',\n",
              " 'economy',\n",
              " 'education',\n",
              " 'eight',\n",
              " 'elected',\n",
              " 'election',\n",
              " 'employee',\n",
              " 'end',\n",
              " 'energy',\n",
              " 'entire',\n",
              " 'even',\n",
              " 'ever',\n",
              " 'every',\n",
              " 'executive',\n",
              " 'fact',\n",
              " 'failed',\n",
              " 'family',\n",
              " 'far',\n",
              " 'federal',\n",
              " 'financial',\n",
              " 'first',\n",
              " 'five',\n",
              " 'food',\n",
              " 'force',\n",
              " 'foreign',\n",
              " 'former',\n",
              " 'found',\n",
              " 'four',\n",
              " 'free',\n",
              " 'fund',\n",
              " 'funding',\n",
              " 'gas',\n",
              " 'gave',\n",
              " 'general',\n",
              " 'get',\n",
              " 'getting',\n",
              " 'give',\n",
              " 'given',\n",
              " 'go',\n",
              " 'going',\n",
              " 'gone',\n",
              " 'got',\n",
              " 'gov',\n",
              " 'government',\n",
              " 'governor',\n",
              " 'great',\n",
              " 'group',\n",
              " 'growth',\n",
              " 'gun',\n",
              " 'ha',\n",
              " 'half',\n",
              " 'health',\n",
              " 'help',\n",
              " 'helped',\n",
              " 'high',\n",
              " 'higher',\n",
              " 'highest',\n",
              " 'history',\n",
              " 'home',\n",
              " 'hour',\n",
              " 'house',\n",
              " 'illegal',\n",
              " 'immigrant',\n",
              " 'immigration',\n",
              " 'including',\n",
              " 'income',\n",
              " 'increase',\n",
              " 'increased',\n",
              " 'individual',\n",
              " 'industry',\n",
              " 'insurance',\n",
              " 'interest',\n",
              " 'iran',\n",
              " 'iraq',\n",
              " 'island',\n",
              " 'issue',\n",
              " 'ive',\n",
              " 'jersey',\n",
              " 'keep',\n",
              " 'kid',\n",
              " 'killed',\n",
              " 'know',\n",
              " 'largest',\n",
              " 'last',\n",
              " 'law',\n",
              " 'le',\n",
              " 'leader',\n",
              " 'least',\n",
              " 'left',\n",
              " 'legislation',\n",
              " 'legislature',\n",
              " 'let',\n",
              " 'level',\n",
              " 'life',\n",
              " 'like',\n",
              " 'lobbyist',\n",
              " 'local',\n",
              " 'lost',\n",
              " 'lot',\n",
              " 'lower',\n",
              " 'lowest',\n",
              " 'made',\n",
              " 'majority',\n",
              " 'make',\n",
              " 'making',\n",
              " 'man',\n",
              " 'mandate',\n",
              " 'many',\n",
              " 'marijuana',\n",
              " 'marriage',\n",
              " 'massachusetts',\n",
              " 'mccain',\n",
              " 'mean',\n",
              " 'medicaid',\n",
              " 'medical',\n",
              " 'medicare',\n",
              " 'member',\n",
              " 'men',\n",
              " 'mexico',\n",
              " 'middle',\n",
              " 'military',\n",
              " 'million',\n",
              " 'milwaukee',\n",
              " 'minimum',\n",
              " 'mitt',\n",
              " 'money',\n",
              " 'month',\n",
              " 'much',\n",
              " 'muslim',\n",
              " 'nation',\n",
              " 'national',\n",
              " 'nearly',\n",
              " 'need',\n",
              " 'never',\n",
              " 'new',\n",
              " 'next',\n",
              " 'north',\n",
              " 'nothing',\n",
              " 'nuclear',\n",
              " 'number',\n",
              " 'obama',\n",
              " 'obamacare',\n",
              " 'obamas',\n",
              " 'office',\n",
              " 'official',\n",
              " 'ohio',\n",
              " 'oil',\n",
              " 'one',\n",
              " 'opposed',\n",
              " 'oregon',\n",
              " 'paid',\n",
              " 'parenthood',\n",
              " 'part',\n",
              " 'party',\n",
              " 'passed',\n",
              " 'past',\n",
              " 'pay',\n",
              " 'paying',\n",
              " 'pension',\n",
              " 'people',\n",
              " 'per',\n",
              " 'percent',\n",
              " 'person',\n",
              " 'place',\n",
              " 'plan',\n",
              " 'planned',\n",
              " 'point',\n",
              " 'police',\n",
              " 'policy',\n",
              " 'political',\n",
              " 'poll',\n",
              " 'population',\n",
              " 'position',\n",
              " 'poverty',\n",
              " 'power',\n",
              " 'president',\n",
              " 'presidential',\n",
              " 'private',\n",
              " 'program',\n",
              " 'project',\n",
              " 'property',\n",
              " 'proposal',\n",
              " 'proposed',\n",
              " 'public',\n",
              " 'put',\n",
              " 'raise',\n",
              " 'raised',\n",
              " 'raising',\n",
              " 'rate',\n",
              " 'received',\n",
              " 'recent',\n",
              " 'record',\n",
              " 'reform',\n",
              " 'report',\n",
              " 'republican',\n",
              " 'resident',\n",
              " 'result',\n",
              " 'revenue',\n",
              " 'rhode',\n",
              " 'right',\n",
              " 'romney',\n",
              " 'rubio',\n",
              " 'rule',\n",
              " 'run',\n",
              " 'running',\n",
              " 'said',\n",
              " 'salary',\n",
              " 'sale',\n",
              " 'save',\n",
              " 'school',\n",
              " 'second',\n",
              " 'secretary',\n",
              " 'sector',\n",
              " 'security',\n",
              " 'seen',\n",
              " 'senate',\n",
              " 'senator',\n",
              " 'senior',\n",
              " 'sent',\n",
              " 'service',\n",
              " 'seven',\n",
              " 'show',\n",
              " 'signed',\n",
              " 'since',\n",
              " 'single',\n",
              " 'six',\n",
              " 'small',\n",
              " 'social',\n",
              " 'spend',\n",
              " 'spending',\n",
              " 'spent',\n",
              " 'state',\n",
              " 'still',\n",
              " 'stimulus',\n",
              " 'stop',\n",
              " 'street',\n",
              " 'student',\n",
              " 'study',\n",
              " 'support',\n",
              " 'supported',\n",
              " 'supreme',\n",
              " 'system',\n",
              " 'take',\n",
              " 'taken',\n",
              " 'taking',\n",
              " 'tax',\n",
              " 'taxpayer',\n",
              " 'teacher',\n",
              " 'term',\n",
              " 'terrorist',\n",
              " 'texas',\n",
              " 'thats',\n",
              " 'theyre',\n",
              " 'thing',\n",
              " 'think',\n",
              " 'thousand',\n",
              " 'three',\n",
              " 'time',\n",
              " 'today',\n",
              " 'took',\n",
              " 'top',\n",
              " 'total',\n",
              " 'trade',\n",
              " 'trillion',\n",
              " 'troop',\n",
              " 'tuition',\n",
              " 'twice',\n",
              " 'two',\n",
              " 'unemployment',\n",
              " 'union',\n",
              " 'united',\n",
              " 'university',\n",
              " 'use',\n",
              " 'used',\n",
              " 'veteran',\n",
              " 'vote',\n",
              " 'voted',\n",
              " 'voter',\n",
              " 'voting',\n",
              " 'wa',\n",
              " 'wage',\n",
              " 'wall',\n",
              " 'want',\n",
              " 'war',\n",
              " 'water',\n",
              " 'weapon',\n",
              " 'week',\n",
              " 'went',\n",
              " 'weve',\n",
              " 'whether',\n",
              " 'white',\n",
              " 'wisconsin',\n",
              " 'without',\n",
              " 'woman',\n",
              " 'work',\n",
              " 'worker',\n",
              " 'working',\n",
              " 'world',\n",
              " 'worst',\n",
              " 'would',\n",
              " 'year',\n",
              " 'york',\n",
              " 'young',\n",
              " 'youre']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4d9mZ7nSSGH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fmt_string = '{:f}={}'\n",
        "ndata = []\n",
        "with open('test.txt','w') as f:\n",
        "    for _,row in df.iterrows():\n",
        "        tup = tuple(w for w in row.statement if w in kept)\n",
        "        if len(tup) < 10: continue\n",
        "        print(fmt_string.format(row.label,json.dumps(tup)),file=f)\n",
        "        ndata.append((tup,row.label))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ev6gvWHSSGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fdata = {\n",
        "    'w2idx':dict((k,v) for v,k in enumerate(kept)),\n",
        "    'data':ndata\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wyMdKCw-SSGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('test.json','w') as f:\n",
        "    json.dump(fdata,f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMkGGSZtSSGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 0\n",
        "largest = None\n",
        "for tup,t in fdata['data']:\n",
        "    if len(tup) > maxlen:\n",
        "        maxlen = len(tup)\n",
        "        largest = tup"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M60TAGjTSSGZ",
        "colab_type": "code",
        "colab": {},
        "outputId": "8de2fdc1-505c-4829-b170-4ffd102f8a11"
      },
      "source": [
        "largest"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('hospital',\n",
              " 'doctor',\n",
              " 'used',\n",
              " 'far',\n",
              " 'country',\n",
              " 'many',\n",
              " 'country',\n",
              " 'former',\n",
              " 'governor',\n",
              " 'massachusetts',\n",
              " 'republican',\n",
              " 'news',\n",
              " 'obamacare',\n",
              " 'cut',\n",
              " 'senior',\n",
              " 'medicare',\n",
              " 'medicare',\n",
              " 'republican',\n",
              " 'republican',\n",
              " 'campaign',\n",
              " 'email',\n",
              " 'many',\n",
              " 'federal',\n",
              " 'employee',\n",
              " 'cost',\n",
              " 'taxpayer',\n",
              " 'million',\n",
              " 'spends',\n",
              " 'million',\n",
              " 'year',\n",
              " 'child',\n",
              " 'education',\n",
              " 'democrat',\n",
              " 'campaign',\n",
              " 'milwaukee',\n",
              " 'county',\n",
              " 'citizen',\n",
              " 'point',\n",
              " 'center',\n",
              " 'mass',\n",
              " 'best',\n",
              " 'option',\n",
              " 'crime',\n",
              " 'gun',\n",
              " 'wisconsin',\n",
              " 'campaign',\n",
              " 'ad',\n",
              " 'almost',\n",
              " 'percent',\n",
              " 'total',\n",
              " 'income',\n",
              " 'planned',\n",
              " 'parenthood',\n",
              " 'abortion',\n",
              " 'abortion',\n",
              " 'state',\n",
              " 'representative',\n",
              " 'republican',\n",
              " 'committee',\n",
              " 'united',\n",
              " 'state',\n",
              " 'ha',\n",
              " 'highest',\n",
              " 'rate',\n",
              " 'poverty',\n",
              " 'almost',\n",
              " 'country',\n",
              " 'earth',\n",
              " 'child',\n",
              " 'poverty',\n",
              " 'senator',\n",
              " 'independent',\n",
              " 'democratic',\n",
              " 'debate',\n",
              " 'governor',\n",
              " 'program',\n",
              " 'allowed',\n",
              " 'undocumented',\n",
              " 'people',\n",
              " 'use',\n",
              " 'personal',\n",
              " 'tax',\n",
              " 'number',\n",
              " 'receive',\n",
              " 'driver',\n",
              " 'license',\n",
              " 'immigration',\n",
              " 'transportation',\n",
              " 'worker',\n",
              " 'rhode',\n",
              " 'island',\n",
              " 'rhode',\n",
              " 'island',\n",
              " 'news',\n",
              " 'illegal',\n",
              " 'alien',\n",
              " 'cost',\n",
              " 'state',\n",
              " 'rhode',\n",
              " 'island',\n",
              " 'million',\n",
              " 'year',\n",
              " 'crime',\n",
              " 'education',\n",
              " 'immigration',\n",
              " 'tax',\n",
              " 'president',\n",
              " 'rhode',\n",
              " 'immigration',\n",
              " 'law',\n",
              " 'rhode',\n",
              " 'island',\n",
              " 'voted',\n",
              " 'congress',\n",
              " 'would',\n",
              " 'paid',\n",
              " 'government',\n",
              " 'shut',\n",
              " 'troop',\n",
              " 'would',\n",
              " 'paid',\n",
              " 'military',\n",
              " 'democrat',\n",
              " 'debate',\n",
              " 'congress',\n",
              " 'current',\n",
              " 'spending',\n",
              " 'level',\n",
              " 'cut',\n",
              " 'percent',\n",
              " 'could',\n",
              " 'balance',\n",
              " 'budget',\n",
              " 'five',\n",
              " 'year',\n",
              " 'deficit',\n",
              " 'republican',\n",
              " 'every',\n",
              " 'wisconsin',\n",
              " 'vote',\n",
              " 'give',\n",
              " 'amount',\n",
              " 'pay',\n",
              " 'state',\n",
              " 'employee',\n",
              " 'labor',\n",
              " 'speaker',\n",
              " 'state',\n",
              " 'wisconsin',\n",
              " 'republican',\n",
              " 'news',\n",
              " 'rubio',\n",
              " 'fund',\n",
              " 'raised',\n",
              " 'went',\n",
              " 'candidate',\n",
              " 'elected',\n",
              " 'office')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzNFMVSGSSGd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}