{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "import string, parse,json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
    "options_file = \"./elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
    "weight_file = \"./elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
    "elmo = Elmo(options_file, weight_file, 1, dropout=0) #1 representation only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "removables = []\n",
    "removables += nltk.corpus.stopwords.words('english')\n",
    "removables += [w.lower() for w in nltk.corpus.names.words()]\n",
    "removables += ['hi','trump']\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "#data fed to vectorizer is already cleaned but maybe TODO use their params instead\n",
    "#vectorizer = TfidfVectorizer(max_features=400)\n",
    "vectorizer = CountVectorizer(max_features=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'name battery car dead better programming'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#much info was lost\n",
    "#after more reading, i realised i never needed to do this, will just use tfidfvectorizer\n",
    "def filterSent(s,freq=None):\n",
    "    s = s.lower()\n",
    "    s = nltk.word_tokenize(s)\n",
    "    s = tuple(lemmatizer.lemmatize(w) for w in s if w.isalpha())\n",
    "    s = tuple(w for w in s if w not in removables)\n",
    "    if freq != None:\n",
    "        for w in s: \n",
    "            if w in freq: freq[w] += 1\n",
    "            else: freq[w] = 1\n",
    "    return ' '.join(s)\n",
    "filterSent(\"hi there my name is jOhn henry battery car dead better programming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#freq = {}\n",
    "formatter = lambda x:(filterSent(x.statement),liar_score[x.label])\n",
    "#freq = OrderedDict(sorted(freq.items(),key=lambda x:x[1],reverse=True))\n",
    "#kept = list(freq.keys())[:800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_raw = './raw/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_headers = ('id','label','statement','subjects','speaker','job_title','state','party','barely_true_counts','false_counts','half_true_counts','mostly_true_counts','pants_on_fire_counts','context')\n",
    "liar_train = pd.read_csv(path_to_raw+'liar_dataset/train.tsv',delimiter='\\t',header=None,names=liar_headers)\n",
    "#counts refer to the speaker's reliability as a whole, interestingly excluding true counts. \n",
    "#will only be using statement & label\n",
    "#print(set(liar_train.label))\n",
    "#assuming linear scale\n",
    "liar_score = {'true':1,\n",
    "              'mostly-true':1,\n",
    "              'half-true':1,\n",
    "              'barely-true':0,\n",
    "              'false':0,\n",
    "              'pants-fire':0\n",
    "             }\n",
    "traindf = liar_train.loc[:,('statement','label')].apply(formatter,axis=1,result_type='broadcast')\n",
    "ndata = vectorizer.fit_transform(traindf.statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "liar_test = pd.read_csv(path_to_raw+'liar_dataset/test.tsv',delimiter='\\t',header=None,names=liar_headers)\n",
    "liar_score = {'true':1,\n",
    "              'mostly-true':2,\n",
    "              'half-true':3,\n",
    "              'barely-true':4,\n",
    "              'false':5,\n",
    "              'pants-fire':6\n",
    "             }\n",
    "testdf = liar_test.loc[:,('statement','label')].apply(formatter,axis=1,result_type='broadcast')\n",
    "tdata = vectorizer.transform(testdf.statement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "clf.fit(ndata.toarray(),np.array(traindf.label,dtype=int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "$ Torch: not enough memory: you tried to allocate 7GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-10818fed55d6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msentences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtraindf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcharacter_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_to_ids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melmo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharacter_ids\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#[representation][sent_no][word_no (padded)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[1;31m# run the biLM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[0mbilm_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreshaped_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreshaped_word_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m         \u001b[0mlayer_activations\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'activations'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m         \u001b[0mmask_with_bos_eos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbilm_output\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs, word_inputs)\u001b[0m\n\u001b[0;32m    605\u001b[0m                 \u001b[0mtype_representation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'token_embedding'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 607\u001b[1;33m             \u001b[0mtoken_embedding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_token_embedder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    608\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mask'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m             \u001b[0mtype_representation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoken_embedding\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'token_embedding'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\allennlp\\modules\\elmo.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    374\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_convolutions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mconv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'char_conv_{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m             \u001b[0mconvolved\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcharacter_embedding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m             \u001b[1;31m# (batch_size * sequence_length, n_filters for this width)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0mconvolved\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconvolved\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[1;32m--> 187\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: $ Torch: not enough memory: you tried to allocate 7GB. Buy new RAM! at ..\\aten\\src\\TH\\THGeneral.cpp:201"
     ]
    }
   ],
   "source": [
    "#I would try this if i hadnt almost immediately crashed from lag. maybe its cause its padded. ill take data points within a length range then\n",
    "sentences = traindf.statement.str.split()\n",
    "character_ids = batch_to_ids(sentences)\n",
    "embeddings = elmo(character_ids) #[representation][sent_no][word_no (padded)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-997828254401>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msentences\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m20\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0msentences\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m50\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1553\u001b[0m             \u001b[1;34m\"The truth value of a {0} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m             \"Use a.empty, a.bool(), a.item(), a.any() or a.all().\".format(\n\u001b[1;32m-> 1555\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1556\u001b[0m             )\n\u001b[0;32m   1557\u001b[0m         )\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "sentences[20 < sentences.map(len) < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13654301499605367"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = 0\n",
    "for pred,tgt in zip(clf.predict(tdata.toarray()),np.array(testdf.label)):\n",
    "    if pred==tgt: cor += 1\n",
    "cor/len(testdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abortion',\n",
       " 'according',\n",
       " 'act',\n",
       " 'actually',\n",
       " 'administration',\n",
       " 'affordable',\n",
       " 'agency',\n",
       " 'ago',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'almost',\n",
       " 'already',\n",
       " 'also',\n",
       " 'amendment',\n",
       " 'america',\n",
       " 'american',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'attack',\n",
       " 'average',\n",
       " 'away',\n",
       " 'back',\n",
       " 'background',\n",
       " 'ban',\n",
       " 'bank',\n",
       " 'barack',\n",
       " 'benefit',\n",
       " 'big',\n",
       " 'billion',\n",
       " 'black',\n",
       " 'board',\n",
       " 'border',\n",
       " 'break',\n",
       " 'brown',\n",
       " 'budget',\n",
       " 'bush',\n",
       " 'business',\n",
       " 'buy',\n",
       " 'california',\n",
       " 'called',\n",
       " 'came',\n",
       " 'campaign',\n",
       " 'candidate',\n",
       " 'cant',\n",
       " 'car',\n",
       " 'care',\n",
       " 'cent',\n",
       " 'change',\n",
       " 'check',\n",
       " 'child',\n",
       " 'china',\n",
       " 'citizen',\n",
       " 'city',\n",
       " 'class',\n",
       " 'college',\n",
       " 'combined',\n",
       " 'come',\n",
       " 'community',\n",
       " 'company',\n",
       " 'congress',\n",
       " 'congressional',\n",
       " 'congressman',\n",
       " 'control',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'country',\n",
       " 'county',\n",
       " 'court',\n",
       " 'coverage',\n",
       " 'create',\n",
       " 'created',\n",
       " 'credit',\n",
       " 'crime',\n",
       " 'criminal',\n",
       " 'current',\n",
       " 'cut',\n",
       " 'day',\n",
       " 'deal',\n",
       " 'death',\n",
       " 'debate',\n",
       " 'debt',\n",
       " 'decade',\n",
       " 'defense',\n",
       " 'deficit',\n",
       " 'democrat',\n",
       " 'democratic',\n",
       " 'department',\n",
       " 'didnt',\n",
       " 'district',\n",
       " 'doesnt',\n",
       " 'dollar',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'doubled',\n",
       " 'drug',\n",
       " 'due',\n",
       " 'economic',\n",
       " 'economy',\n",
       " 'education',\n",
       " 'eight',\n",
       " 'elected',\n",
       " 'election',\n",
       " 'employee',\n",
       " 'end',\n",
       " 'energy',\n",
       " 'entire',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'executive',\n",
       " 'fact',\n",
       " 'failed',\n",
       " 'family',\n",
       " 'far',\n",
       " 'federal',\n",
       " 'financial',\n",
       " 'first',\n",
       " 'five',\n",
       " 'food',\n",
       " 'force',\n",
       " 'foreign',\n",
       " 'former',\n",
       " 'found',\n",
       " 'four',\n",
       " 'free',\n",
       " 'fund',\n",
       " 'funding',\n",
       " 'gas',\n",
       " 'gave',\n",
       " 'general',\n",
       " 'get',\n",
       " 'getting',\n",
       " 'give',\n",
       " 'given',\n",
       " 'go',\n",
       " 'going',\n",
       " 'gone',\n",
       " 'got',\n",
       " 'gov',\n",
       " 'government',\n",
       " 'governor',\n",
       " 'great',\n",
       " 'group',\n",
       " 'growth',\n",
       " 'gun',\n",
       " 'ha',\n",
       " 'half',\n",
       " 'health',\n",
       " 'help',\n",
       " 'helped',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highest',\n",
       " 'history',\n",
       " 'home',\n",
       " 'hour',\n",
       " 'house',\n",
       " 'illegal',\n",
       " 'immigrant',\n",
       " 'immigration',\n",
       " 'including',\n",
       " 'income',\n",
       " 'increase',\n",
       " 'increased',\n",
       " 'individual',\n",
       " 'industry',\n",
       " 'insurance',\n",
       " 'interest',\n",
       " 'iran',\n",
       " 'iraq',\n",
       " 'island',\n",
       " 'issue',\n",
       " 'ive',\n",
       " 'jersey',\n",
       " 'keep',\n",
       " 'kid',\n",
       " 'killed',\n",
       " 'know',\n",
       " 'largest',\n",
       " 'last',\n",
       " 'law',\n",
       " 'le',\n",
       " 'leader',\n",
       " 'least',\n",
       " 'left',\n",
       " 'legislation',\n",
       " 'legislature',\n",
       " 'let',\n",
       " 'level',\n",
       " 'life',\n",
       " 'like',\n",
       " 'lobbyist',\n",
       " 'local',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'lower',\n",
       " 'lowest',\n",
       " 'made',\n",
       " 'majority',\n",
       " 'make',\n",
       " 'making',\n",
       " 'man',\n",
       " 'mandate',\n",
       " 'many',\n",
       " 'marijuana',\n",
       " 'marriage',\n",
       " 'massachusetts',\n",
       " 'mccain',\n",
       " 'mean',\n",
       " 'medicaid',\n",
       " 'medical',\n",
       " 'medicare',\n",
       " 'member',\n",
       " 'men',\n",
       " 'mexico',\n",
       " 'middle',\n",
       " 'military',\n",
       " 'million',\n",
       " 'milwaukee',\n",
       " 'minimum',\n",
       " 'mitt',\n",
       " 'money',\n",
       " 'month',\n",
       " 'much',\n",
       " 'muslim',\n",
       " 'nation',\n",
       " 'national',\n",
       " 'nearly',\n",
       " 'need',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'north',\n",
       " 'nothing',\n",
       " 'nuclear',\n",
       " 'number',\n",
       " 'obama',\n",
       " 'obamacare',\n",
       " 'obamas',\n",
       " 'office',\n",
       " 'official',\n",
       " 'ohio',\n",
       " 'oil',\n",
       " 'one',\n",
       " 'opposed',\n",
       " 'oregon',\n",
       " 'paid',\n",
       " 'parenthood',\n",
       " 'part',\n",
       " 'party',\n",
       " 'passed',\n",
       " 'past',\n",
       " 'pay',\n",
       " 'paying',\n",
       " 'pension',\n",
       " 'people',\n",
       " 'per',\n",
       " 'percent',\n",
       " 'person',\n",
       " 'place',\n",
       " 'plan',\n",
       " 'planned',\n",
       " 'point',\n",
       " 'police',\n",
       " 'policy',\n",
       " 'political',\n",
       " 'poll',\n",
       " 'population',\n",
       " 'position',\n",
       " 'poverty',\n",
       " 'power',\n",
       " 'president',\n",
       " 'presidential',\n",
       " 'private',\n",
       " 'program',\n",
       " 'project',\n",
       " 'property',\n",
       " 'proposal',\n",
       " 'proposed',\n",
       " 'public',\n",
       " 'put',\n",
       " 'raise',\n",
       " 'raised',\n",
       " 'raising',\n",
       " 'rate',\n",
       " 'received',\n",
       " 'recent',\n",
       " 'record',\n",
       " 'reform',\n",
       " 'report',\n",
       " 'republican',\n",
       " 'resident',\n",
       " 'result',\n",
       " 'revenue',\n",
       " 'rhode',\n",
       " 'right',\n",
       " 'romney',\n",
       " 'rubio',\n",
       " 'rule',\n",
       " 'run',\n",
       " 'running',\n",
       " 'said',\n",
       " 'salary',\n",
       " 'sale',\n",
       " 'save',\n",
       " 'school',\n",
       " 'second',\n",
       " 'secretary',\n",
       " 'sector',\n",
       " 'security',\n",
       " 'seen',\n",
       " 'senate',\n",
       " 'senator',\n",
       " 'senior',\n",
       " 'sent',\n",
       " 'service',\n",
       " 'seven',\n",
       " 'show',\n",
       " 'signed',\n",
       " 'since',\n",
       " 'single',\n",
       " 'six',\n",
       " 'small',\n",
       " 'social',\n",
       " 'spend',\n",
       " 'spending',\n",
       " 'spent',\n",
       " 'state',\n",
       " 'still',\n",
       " 'stimulus',\n",
       " 'stop',\n",
       " 'street',\n",
       " 'student',\n",
       " 'study',\n",
       " 'support',\n",
       " 'supported',\n",
       " 'supreme',\n",
       " 'system',\n",
       " 'take',\n",
       " 'taken',\n",
       " 'taking',\n",
       " 'tax',\n",
       " 'taxpayer',\n",
       " 'teacher',\n",
       " 'term',\n",
       " 'terrorist',\n",
       " 'texas',\n",
       " 'thats',\n",
       " 'theyre',\n",
       " 'thing',\n",
       " 'think',\n",
       " 'thousand',\n",
       " 'three',\n",
       " 'time',\n",
       " 'today',\n",
       " 'took',\n",
       " 'top',\n",
       " 'total',\n",
       " 'trade',\n",
       " 'trillion',\n",
       " 'troop',\n",
       " 'tuition',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'unemployment',\n",
       " 'union',\n",
       " 'united',\n",
       " 'university',\n",
       " 'use',\n",
       " 'used',\n",
       " 'veteran',\n",
       " 'vote',\n",
       " 'voted',\n",
       " 'voter',\n",
       " 'voting',\n",
       " 'wa',\n",
       " 'wage',\n",
       " 'wall',\n",
       " 'want',\n",
       " 'war',\n",
       " 'water',\n",
       " 'weapon',\n",
       " 'week',\n",
       " 'went',\n",
       " 'weve',\n",
       " 'whether',\n",
       " 'white',\n",
       " 'wisconsin',\n",
       " 'without',\n",
       " 'woman',\n",
       " 'work',\n",
       " 'worker',\n",
       " 'working',\n",
       " 'world',\n",
       " 'worst',\n",
       " 'would',\n",
       " 'year',\n",
       " 'york',\n",
       " 'young',\n",
       " 'youre']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmt_string = '{:f}={}'\n",
    "ndata = []\n",
    "with open('test.txt','w') as f:\n",
    "    for _,row in df.iterrows():\n",
    "        tup = tuple(w for w in row.statement if w in kept)\n",
    "        if len(tup) < 10: continue\n",
    "        print(fmt_string.format(row.label,json.dumps(tup)),file=f)\n",
    "        ndata.append((tup,row.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdata = {\n",
    "    'w2idx':dict((k,v) for v,k in enumerate(kept)),\n",
    "    'data':ndata\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test.json','w') as f:\n",
    "    json.dump(fdata,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 0\n",
    "largest = None\n",
    "for tup,t in fdata['data']:\n",
    "    if len(tup) > maxlen:\n",
    "        maxlen = len(tup)\n",
    "        largest = tup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hospital',\n",
       " 'doctor',\n",
       " 'used',\n",
       " 'far',\n",
       " 'country',\n",
       " 'many',\n",
       " 'country',\n",
       " 'former',\n",
       " 'governor',\n",
       " 'massachusetts',\n",
       " 'republican',\n",
       " 'news',\n",
       " 'obamacare',\n",
       " 'cut',\n",
       " 'senior',\n",
       " 'medicare',\n",
       " 'medicare',\n",
       " 'republican',\n",
       " 'republican',\n",
       " 'campaign',\n",
       " 'email',\n",
       " 'many',\n",
       " 'federal',\n",
       " 'employee',\n",
       " 'cost',\n",
       " 'taxpayer',\n",
       " 'million',\n",
       " 'spends',\n",
       " 'million',\n",
       " 'year',\n",
       " 'child',\n",
       " 'education',\n",
       " 'democrat',\n",
       " 'campaign',\n",
       " 'milwaukee',\n",
       " 'county',\n",
       " 'citizen',\n",
       " 'point',\n",
       " 'center',\n",
       " 'mass',\n",
       " 'best',\n",
       " 'option',\n",
       " 'crime',\n",
       " 'gun',\n",
       " 'wisconsin',\n",
       " 'campaign',\n",
       " 'ad',\n",
       " 'almost',\n",
       " 'percent',\n",
       " 'total',\n",
       " 'income',\n",
       " 'planned',\n",
       " 'parenthood',\n",
       " 'abortion',\n",
       " 'abortion',\n",
       " 'state',\n",
       " 'representative',\n",
       " 'republican',\n",
       " 'committee',\n",
       " 'united',\n",
       " 'state',\n",
       " 'ha',\n",
       " 'highest',\n",
       " 'rate',\n",
       " 'poverty',\n",
       " 'almost',\n",
       " 'country',\n",
       " 'earth',\n",
       " 'child',\n",
       " 'poverty',\n",
       " 'senator',\n",
       " 'independent',\n",
       " 'democratic',\n",
       " 'debate',\n",
       " 'governor',\n",
       " 'program',\n",
       " 'allowed',\n",
       " 'undocumented',\n",
       " 'people',\n",
       " 'use',\n",
       " 'personal',\n",
       " 'tax',\n",
       " 'number',\n",
       " 'receive',\n",
       " 'driver',\n",
       " 'license',\n",
       " 'immigration',\n",
       " 'transportation',\n",
       " 'worker',\n",
       " 'rhode',\n",
       " 'island',\n",
       " 'rhode',\n",
       " 'island',\n",
       " 'news',\n",
       " 'illegal',\n",
       " 'alien',\n",
       " 'cost',\n",
       " 'state',\n",
       " 'rhode',\n",
       " 'island',\n",
       " 'million',\n",
       " 'year',\n",
       " 'crime',\n",
       " 'education',\n",
       " 'immigration',\n",
       " 'tax',\n",
       " 'president',\n",
       " 'rhode',\n",
       " 'immigration',\n",
       " 'law',\n",
       " 'rhode',\n",
       " 'island',\n",
       " 'voted',\n",
       " 'congress',\n",
       " 'would',\n",
       " 'paid',\n",
       " 'government',\n",
       " 'shut',\n",
       " 'troop',\n",
       " 'would',\n",
       " 'paid',\n",
       " 'military',\n",
       " 'democrat',\n",
       " 'debate',\n",
       " 'congress',\n",
       " 'current',\n",
       " 'spending',\n",
       " 'level',\n",
       " 'cut',\n",
       " 'percent',\n",
       " 'could',\n",
       " 'balance',\n",
       " 'budget',\n",
       " 'five',\n",
       " 'year',\n",
       " 'deficit',\n",
       " 'republican',\n",
       " 'every',\n",
       " 'wisconsin',\n",
       " 'vote',\n",
       " 'give',\n",
       " 'amount',\n",
       " 'pay',\n",
       " 'state',\n",
       " 'employee',\n",
       " 'labor',\n",
       " 'speaker',\n",
       " 'state',\n",
       " 'wisconsin',\n",
       " 'republican',\n",
       " 'news',\n",
       " 'rubio',\n",
       " 'fund',\n",
       " 'raised',\n",
       " 'went',\n",
       " 'candidate',\n",
       " 'elected',\n",
       " 'office')"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
